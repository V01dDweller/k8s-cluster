# file: k8s_install.yml
---
- name: Install kubectl locally
  hosts: localhost
  connection: local
  gather_facts: false
  become: true
  tasks:
    - name: Retrieving kubectl latest stable version
      ansible.builtin.uri:
        url: https://dl.k8s.io/release/stable.txt
        method: GET
        return_content: true
      register: kubectl_version

    - name: Displaying kubectl latest stable version
      ansible.builtin.debug:
        msg: Lastest kubectl version is {{ kubectl_version.content }}

    - name: Downloading /usr/local/bin/kubectl {{ kubectl_version.content }}
      ansible.builtin.get_url:
        url: https://dl.k8s.io/release/{{ kubectl_version.content }}/bin/linux/amd64/kubectl
        dest: /usr/local/bin/kubectl
        mode: '0755'
        owner: root
        group: root

- name: Installing Containerd, Docker and Kubernetes tools
  hosts: all
  become: true
  gather_facts: false
  roles:
    - role: hosts_update
      tags:
        - hosts

    - role: ipv6_disable
      tags:
        - ipv6

    - role: containerd_install
      tags:
        - containerd

    # Docker support in Kubernetes is deprecated as of v1.20

    # - role: docker_install
    #   tags:
    #     - docker
    #     - packages

  post_tasks:
    - name: Setting time zone Americas/New_York
      community.general.timezone:
        name: America/New_York
      tags: timezone

    # Disable swap for Kubernetes
    # Thanks to Reddit post: https://www.reddit.com/r/linuxadmin/comments/flzx5r/ansible_how_to_disable_swap/
    - name: Gathering facts
      ansible.builtin.setup:
        filter: ansible_swaptotal_mb
      tags: swap

    - name: Disabling swap
      when: ansible_swaptotal_mb > 0
      tags: swap
      block:
        - name: Disable swap for current session
          ansible.builtin.command: swapoff -a
          become: true
          tags: swap

        - name: Disable swap permanently, persist reboots
          ansible.builtin.replace:
            path: /etc/fstab
            regexp: '^(\s*)([^#\n]+\s+)(\w+\s+)swap(\s+.*)$'
            replace: '#\1\2\3swap\4'
            backup: true
          tags: swap

    - name: Adding Kubernetes signing key
      ansible.builtin.apt_key:
        url: https://pkgs.k8s.io/core:/stable:/v1.32/deb/Release.key
        keyring: /etc/apt/keyrings/kubernetes-apt-keyring.gpg
        state: present
      tags: packages

    - name: Adding Kubernetes repository
      ansible.builtin.apt_repository:
        repo: deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.32/deb/ /
        state: present
        filename: kubernetes.list
      tags: packages

    - name: Setting kubernetes_packages fact
      ansible.builtin.set_fact:
        kubernetes_packages:
          - kubelet
          - kubeadm
          - kubectl
      tags: packages

    - name: Installing kubeadm kubelet and kubectl
      ansible.builtin.apt:
        name: '{{ kubernetes_packages }}'
        state: present
        update_cache: true
      tags: packages

    - name: Issuing apt-mark hold on kubeadm kubelet and kubectl
      ansible.builtin.dpkg_selections:
        name: '{{ package }}'
        selection: hold
      loop: '{{ kubernetes_packages }}'
      loop_control:
        loop_var: package
        label: Holding {{ package }} package
      tags: packages

    - name: Creating /etc/sysctl.d/kubernetes.conf
      ansible.builtin.copy:
        content: |
          net.ipv4.ip_forward = 1
          net.bridge.bridge-nf-call-iptables = 1
        dest: /etc/sysctl.d/kubernetes.conf
        owner: root
        group: root
        mode: '0644'
      notify: Reload sysctl
      tags:
        - packages
        - forwarding

  handlers:
    - name: Issue modprobe overlay
      ansible.builtin.command: modprobe overlay
      changed_when: false

    - name: Reload sysctl
      ansible.builtin.command: sysctl --system
      changed_when: false

- name: Configure the master
  hosts: master
  become: true
  gather_facts: false
  tags: master
  tasks:
    - name: Creating /etc/default/kubelet
      ansible.builtin.copy:
        content: |
          KUBELET_EXTRA_ARGS="--cgroup-driver=cgroupfs"
        dest: /etc/default/kubelet
        owner: root
        group: root
        mode: '0644'
      notify: Restart kubelet

    - name: Flushing handlers now to create /etc/systemd/system/kubelet.service.d/10-kubeadm.conf
      ansible.builtin.meta: flush_handlers

    - name: Updating /etc/systemd/system/kubelet.service.d/10-kubeadm.conf
      ansible.builtin.copy:
        content: |
          # Note: This dropin only works with kubeadm and kubelet v1.11+
          [Service]
          Environment="KUBELET_KUBECONFIG_ARGS=--bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --kubeconfig=/etc/kubernetes/kubelet.conf"
          Environment="KUBELET_CONFIG_ARGS=--config=/var/lib/kubelet/config.yaml"
          Environment="KUBELET_EXTRA_ARGS=--fail-swap-on=false"
          # This is a file that "kubeadm init" and "kubeadm join" generates at runtime, populating the KUBELET_KUBEADM_ARGS variable dynamically
          EnvironmentFile=-/var/lib/kubelet/kubeadm-flags.env
          # This is a file that the user can use for overrides of the kubelet args as a last resort. Preferably, the user should use
          # the .NodeRegistration.KubeletExtraArgs object in the configuration files instead. KUBELET_EXTRA_ARGS should be sourced from this file.
          EnvironmentFile=-/etc/default/kubelet
          ExecStart=
          ExecStart=/usr/bin/kubelet $KUBELET_KUBECONFIG_ARGS $KUBELET_CONFIG_ARGS $KUBELET_KUBEADM_ARGS $KUBELET_EXTRA_ARGS
        dest: /etc/systemd/system/kubelet.service.d/10-kubeadm.conf
        owner: root
        group: root
        mode: '0644'
      notify: Restart kubelet
      tags: never

    - name: Saving the master hostname from the inventory
      ansible.builtin.set_fact:
        master_hostname: "{{ hostvars[groups['master'][0]].ansible_host }}"

    - name: Who's da master?
      ansible.builtin.debug:
        msg: The master is {{ master_hostname }}

    - name: Initializing the cluster via kubeadmin (this may take some time)
      ansible.builtin.shell: |
        set -o pipefail
        kubeadm init \
        --pod-network-cidr=10.244.0.0/16 \
        --control-plane-endpoint={{ master_hostname }} \
        --apiserver-advertise-address={{ master_hostname }}
      args:
        executable: /bin/bash
        creates: /etc/kubernetes/admin.conf
      register: kubeadm_init

    - name: Displaying kubeadm init output
      ansible.builtin.debug:
        msg: '{{ kubeadm_init.stdout }}'

    - name: Creating $HOME/.kube
      ansible.builtin.file:
        path: /home/{{ ansible_user }}/.kube
        state: directory
        owner: '{{ ansible_user }}'
        group: '{{ ansible_user }}'
        mode: '0755'

    - name: Creating $HOME/.kube admin.conf
      ansible.builtin.copy:
        src: /etc/kubernetes/admin.conf
        remote_src: true
        dest: /home/{{ ansible_user }}/.kube/config
        owner: '{{ ansible_user }}'
        group: '{{ ansible_user }}'
        mode: '0644'

    - name: Enabling bridging and iptables for flannel
      ansible.builtin.shell: |
        set -o pipefail
        modprobe bridge
        echo "net.bridge.bridge-nf-call-iptables = 1" >> /etc/sysctl.conf
        modprobe br_netfilter
        sysctl -p /etc/sysctl.conf
      args:
        executable: /bin/bash
      tags: flannel

    - name: Downloading flannel manifest
      ansible.builtin.get_url:
        url: https://github.com/flannel-io/flannel/releases/latest/download/kube-flannel.yml
        dest: /etc/kubernetes/kube-flannel.yml
        mode: '0644'
        owner: root
        group: root
      tags: flannel

    # NOTE: This task is needed because the Vagrantfile adds a 2nd nic
    # for the private network. Adding the --iface=eth1 to the flannel
    # manifest will allow flannel to use the private network for the
    # overlay network.
    # Reference: https://stackoverflow.com/questions/47845739/configuring-flannel-to-use-a-non-default-interface-in-kubernetes
    - name: Updating kube-flannel.yml with "--iface=eth1"
      ansible.builtin.lineinfile:
        path: /etc/kubernetes/kube-flannel.yml
        line: '        - --iface=eth1'
        insertafter: '        - --kube-subnet-mgr'
        state: present
        backup: true
      tags: flannel

    - name: Installing Flannel
      ansible.builtin.shell: |
        set -o pipefail
        export KUBECONFIG=/etc/kubernetes/admin.conf
        kubectl apply -f /etc/kubernetes/kube-flannel.yml
      args:
        executable: /bin/bash
      register: flannel_install
      tags: flannel

        #  - name: Installing Flannel
        #    ansible.builtin.shell: |
        #      set -o pipefail
        #      export KUBECONFIG=/etc/kubernetes/admin.conf
        #      kubectl apply -f https://github.com/flannel-io/flannel/releases/latest/download/kube-flannel.yml
        #    args:
        #      executable: /bin/bash
        #    register: flannel_install
        #    tags: flannel

    - name: Displaying flannel install output
      ansible.builtin.debug:
        msg: '{{ flannel_install.stdout }}'

    - name: Waiting for the cluster to be ready
      ansible.builtin.shell: |
        set -o pipefail
        export KUBECONFIG=/etc/kubernetes/admin.conf
        kubectl get nodes
      args:
        executable: /bin/bash
      register: node_status
      until:
        - '"Ready" in node_status.stdout'
      retries: 10
      delay: 3
      tags: flannel

        # # Base on Cilium Quick Installation guide found
        # # here: https://docs.cilium.io/en/stable/gettingstarted/k8s-install-default/
        # - name: Installing the Cilium CLI
        #   ansible.builtin.shell: |
        #     CILIUM_CLI_VERSION=$(curl -s https://raw.githubusercontent.com/cilium/cilium-cli/main/stable.txt)
        #     CLI_ARCH=amd64
        #     if [ "$(uname -m)" = "aarch64" ]; then CLI_ARCH=arm64; fi
        #     curl -L --fail --remote-name-all https://github.com/cilium/cilium-cli/releases/download/${CILIUM_CLI_VERSION}/cilium-linux-${CLI_ARCH}.tar.gz{,.sha256sum}
        #     sha256sum --check cilium-linux-${CLI_ARCH}.tar.gz.sha256sum
        #     sudo tar xzvfC cilium-linux-${CLI_ARCH}.tar.gz /usr/local/bin
        #     rm cilium-linux-${CLI_ARCH}.tar.gz{,.sha256sum}
        #   args:
        #     executable: /bin/bash
        #     creates: /usr/local/bin/cilium
        #   become: false
        #   register: cilium_cli_install
        #   tags: cilium

        # - name: Displaying cilium cli install output
        #   ansible.builtin.debug:
        #     msg: '{{ cilium_cli_install.stdout }}'
        #   tags: cilium

        # - name: Installing Cilium
        #   ansible.builtin.shell: |
        #     cilium install --version 1.16.5
        #   args:
        #     executable: /bin/bash
        #     creates: /opt/cni/bin/cilium-cni
        #   become: false
        #   register: cilium_install
        #   tags: cilium

    - name: Getting cluster status
      ansible.builtin.shell: |
        set -o pipefail
        kubectl cluster-info
        kubectl get nodes
      args:
        executable: /bin/bash
      become: false
      register: cluster_info
      changed_when: false
      ignore_errors: true

    - name: Displaying cluster info
      ansible.builtin.debug:
        msg: '{{ cluster_info.stdout }}'

  handlers:
    - name: Restart kubelet
      ansible.builtin.service:
        name: kubelet
        state: restarted
        daemon_reload: true

- name: Configure the nodes
  hosts: nodes
  become: true
  gather_facts: false
  tags: nodes
  tasks:
    - name: Preparing to join nodes to cluster
      run_once: true
      become: false
      block:
        - name: Retrieving master name and ip from inventory
          ansible.builtin.set_fact:
            master_hostname: "{{ hostvars[groups['master'][0]].inventory_hostname }}"
            master_ip: "{{ hostvars[groups['master'][0]].ansible_host }}"
          delegate_to: localhost

        - name: Retrieving the join command
          ansible.builtin.shell: |
            set -o pipefail
            kubeadm token create --print-join-command
          args:
            executable: /bin/bash
          delegate_to: '{{ master_hostname }}'
          register: kubeadm_join_command
          changed_when: false

        - name: Displaying the join command
          ansible.builtin.debug:
            msg: '{{ kubeadm_join_command.stdout }}'
          tags: never

        - name: Saving the tokens
          ansible.builtin.set_fact:
            token: '{{ kubeadm_join_command.stdout.split(" ")[4] }}'
            cert_hash: '{{ kubeadm_join_command.stdout.split(" ")[6] }}'

        - name: Displaying the tokens
          ansible.builtin.debug:
            msg: |
              Token: {{ token }}
              Discovery token cert hash: {{ cert_hash }}
          tags: never

    - name: Disabling apparmor service
      ansible.builtin.service:
        name: apparmor
        state: stopped
        enabled: false
        daemon_reload: true

    - name: Joining nodes to cluster
      ansible.builtin.shell: |
        set -o pipefail
        kubeadm join {{ master_ip }}:6443 --token {{ token }} --discovery-token-ca-cert-hash {{ cert_hash }}
      args:
        executable: /bin/bash
        creates: /etc/kubernetes/kubelet.conf
      register: node_status

    - name: Displaying node status
      ansible.builtin.debug:
        msg: '{{ node_status.stdout }}'
...
# vim: ft=ansible:syntax=yaml.ansible:number:nowrap nospell
